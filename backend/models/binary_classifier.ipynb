{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install lightgbm==4.3.0\n",
        "\n",
        "import json, re, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from lightgbm import LGBMClassifier\n",
        "import joblib\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M1sA61FVtxp",
        "outputId": "71f1ad57-bfda-4b68-d0c9-d9985e128512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/merged_shuffled_20250822_185836.csv\"\n",
        "target_col = \"Label\"\n",
        "\n",
        "head_df = pd.read_csv(file_path, nrows=5000)\n",
        "cols = head_df.columns.tolist()\n",
        "assert target_col in cols, \"Label not found!\"\n",
        "\n",
        "allow_prefixes = (\"frame.\", \"radiotap.\", \"wlan.\", \"wlan_radio.\")\n",
        "\n",
        "block_exact = set([\n",
        "    \"frame.number\", \"frame.time\", \"frame.time_epoch\",\n",
        "    \"radiotap.mactime\", \"radiotap.present.tsft\", \"radiotap.timestamp.ts\",\n",
        "    \"wlan.bssid\",\"wlan.da\",\"wlan.ra\",\"wlan.sa\",\"wlan.ta\",\"wlan.ssid\",\"wlan.tag\",\"wlan.tag.length\",\n",
        "    \"wlan.analysis.kck\",\"wlan.analysis.kek\",\"wlan.rsn.ie.gtk.key\",\"wlan.rsn.ie.igtk.key\",\"wlan.rsn.ie.pmkid\",\n",
        "    \"wlan.fixed.timestamp\",\"wlan_rsna_eapol.keydes.msgnr\",\"wlan_rsna_eapol.keydes.data\",\n",
        "    \"wlan_rsna_eapol.keydes.data_len\",\"wlan_rsna_eapol.keydes.key_info.key_mic\",\"wlan_rsna_eapol.keydes.nonce\",\n",
        "])\n",
        "\n",
        "block_patterns = [\n",
        "    r\"(?i)\\b(bssid|ssid|mac|addr|oui|vendor|station|ra|ta|sa|da)\\b\",\n",
        "    r\"(?i)^(ip\\.|ipv6\\.|arp|tcp\\.|udp\\.|dns|http|json|ssh|tls|smb2?|nbns|nbss|ldap|dhcp|mdns|ssdp)\\b\",\n",
        "    r\"(?i)(payload|data\\.data|llc|eapol|key|nonce|pmkid|gtk|igtk|kck|kek)\",\n",
        "    r\"(?i)(pcap|source_file|capture|interface)\",\n",
        "    r\"(?i)(start_tsf|end_tsf|timestamp)\",\n",
        "]\n",
        "\n",
        "def allowed(col: str) -> bool:\n",
        "    if col == target_col:\n",
        "        return True\n",
        "    low = col.lower()\n",
        "    if not low.startswith(allow_prefixes):\n",
        "        return False\n",
        "    if col in block_exact:\n",
        "        return False\n",
        "    for pat in block_patterns:\n",
        "        if re.search(pat, low):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "keep_cols = [c for c in cols if allowed(c)]\n",
        "if target_col not in keep_cols:\n",
        "    keep_cols.append(target_col)\n",
        "\n",
        "print(\"عدد الأعمدة قبل:\", len(cols), \"| بعد:\", len(keep_cols))\n",
        "print(\"أول 30 عمود:\", keep_cols[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "W6NvDa9uXh5t",
        "outputId": "3bc5c494-a6ca-4a15-a5c3-495fe5afd20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1080710191.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhead_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Label not found!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path, usecols=keep_cols)\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "print(\"شكل البيانات:\", df.shape)\n",
        "print(\"عدد الأعمدة:\", len(df.columns))\n",
        "df.head(3)\n",
        "\n",
        "y_bin = (df[target_col].astype(str).str.lower() != \"normal\").astype(int)\n",
        "X = df.drop(columns=[target_col])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y_bin, test_size=0.2, stratify=y_bin, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_tr.shape, \"Test size:\", X_te.shape)\n",
        "\n",
        "cat_cols = X_tr.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
        "num_cols = X_tr.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(\"أعمدة رقمية:\", len(num_cols), \"| فئوية:\", len(cat_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRMbzl6uaf5R",
        "outputId": "e39e5ffe-a37e-48a2-cf6a-e5be17098f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-355289944.py:1: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, usecols=keep_cols)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "شكل البيانات: (578678, 39)\n",
            "عدد الأعمدة: 39\n",
            "Train size: (462942, 38) Test size: (115736, 38)\n",
            "أعمدة رقمية: 34 | فئوية: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Encoder\n",
        "def coerce_mixed_columns(df_train, df_test, hex_ok=True, thresh=0.8):\n",
        "    df_train = df_train.copy()\n",
        "    df_test  = df_test.copy()\n",
        "    num_cols, cat_cols = [], []\n",
        "    for c in df_train.columns:\n",
        "        s_tr, s_te = df_train[c], df_test[c]\n",
        "        if s_tr.dtype == object or str(s_tr.dtype).startswith(\"string\"):\n",
        "            st_tr = s_tr.astype(str)\n",
        "            if hex_ok:\n",
        "                st_tr_num = pd.to_numeric(st_tr.str.replace(r\"^\\s*0x\", \"\", regex=True), errors=\"coerce\")\n",
        "            else:\n",
        "                st_tr_num = pd.to_numeric(st_tr, errors=\"coerce\")\n",
        "            if st_tr_num.notna().mean() >= thresh:\n",
        "                st_te = s_te.astype(str)\n",
        "                st_te_num = pd.to_numeric(st_te.str.replace(r\"^\\s*0x\", \"\", regex=True), errors=\"coerce\")\n",
        "                df_train[c] = st_tr_num.astype(\"float32\")\n",
        "                df_test[c]  = st_te_num.astype(\"float32\")\n",
        "                num_cols.append(c)\n",
        "            else:\n",
        "                df_train[c] = s_tr.astype(\"string\")\n",
        "                df_test[c]  = s_te.astype(\"string\")\n",
        "                cat_cols.append(c)\n",
        "        else:\n",
        "            num_cols.append(c)\n",
        "    return df_train, df_test, num_cols, cat_cols\n",
        "\n",
        "X_tr, X_te, num_cols, cat_cols = coerce_mixed_columns(X_tr, X_te, hex_ok=True, thresh=0.8)\n",
        "\n",
        "na_ratio = X_tr.isna().mean()\n",
        "drop_almost = na_ratio[na_ratio > 0.98].index.tolist()\n",
        "if drop_almost:\n",
        "    X_tr.drop(columns=drop_almost, inplace=True, errors=\"ignore\")\n",
        "    X_te.drop(columns=[c for c in drop_almost if c in X_te.columns], inplace=True, errors=\"ignore\")\n",
        "    num_cols = [c for c in num_cols if c not in drop_almost]\n",
        "    cat_cols = [c for c in cat_cols if c not in drop_almost]\n",
        "print(\"بعد التوحيد → رقمية:\", len(num_cols), \"فئوية:\", len(cat_cols))\n",
        "\n",
        "# preprocessor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "num_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
        "cat_tf = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ordenc\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
        "])\n",
        "prep = ColumnTransformer(\n",
        "    [(\"num\", num_tf, num_cols)] + ([(\"cat\", cat_tf, cat_cols)] if cat_cols else []),\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "prep.fit(X_tr)\n",
        "X_tr_t = prep.transform(X_tr)\n",
        "X_te_t = prep.transform(X_te)\n",
        "\n",
        "# LightGBM,early stopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "classes = np.unique(y_tr)\n",
        "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_tr)\n",
        "class_to_w = dict(zip(classes, cw))\n",
        "sample_weight = np.array([class_to_w[v] for v in y_tr])\n",
        "\n",
        "lgb_bin = LGBMClassifier(\n",
        "    objective=\"binary\",\n",
        "    n_estimators=5000,        #early stopping\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=63,\n",
        "    max_depth=-1,\n",
        "    min_child_samples=50,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgb_bin.fit(\n",
        "    X_tr_t, y_tr,\n",
        "    sample_weight=sample_weight,\n",
        "    eval_set=[(X_te_t, y_te)],\n",
        "    eval_metric=\"auc\",\n",
        "    callbacks=[lgb.early_stopping(150, verbose=False)]\n",
        ")\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "y_pred = lgb_bin.predict(X_te_t)\n",
        "cm = confusion_matrix(y_te, y_pred)\n",
        "report = classification_report(y_te, y_pred, digits=4, target_names=[\"Normal\",\"Attack\"])\n",
        "macro_f1 = f1_score(y_te, y_pred, average=\"macro\")\n",
        "\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "fpr = fp / (fp + tn + 1e-9)\n",
        "recall_attack = tp / (tp + fn + 1e-9)\n",
        "\n",
        "print(report)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "print(f\"Macro-F1={macro_f1:.4f} | FPR(Normal)={fpr:.4f} | Recall(Attack)={recall_attack:.4f}\")\n",
        "\n",
        "from pathlib import Path\n",
        "import joblib, json\n",
        "art = Path(\"/content/artifacts\"); art.mkdir(exist_ok=True)\n",
        "joblib.dump(prep, art/\"preprocessor_stage1.joblib\")\n",
        "joblib.dump(lgb_bin, art/\"stage1_lgbm_binary.joblib\")\n",
        "with open(art/\"feature_list_stage1.json\",\"w\") as f: json.dump(list(X_tr.columns), f, indent=2)\n",
        "print(\"Saved to:\", art)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtX1x5etar29",
        "outputId": "89ee51bc-5b51-446c-d719-426ff2d8678c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "بعد التوحيد → رقمية: 30 فئوية: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 83960, number of negative: 378982\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046891 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2001\n",
            "[LightGBM] [Info] Number of data points in the train set: 462942, number of used features: 26\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal     0.9996    0.9988    0.9992     94746\n",
            "      Attack     0.9946    0.9983    0.9965     20990\n",
            "\n",
            "    accuracy                         0.9987    115736\n",
            "   macro avg     0.9971    0.9986    0.9978    115736\n",
            "weighted avg     0.9987    0.9987    0.9987    115736\n",
            "\n",
            "Confusion matrix:\n",
            " [[94633   113]\n",
            " [   35 20955]]\n",
            "Macro-F1=0.9978 | FPR(Normal)=0.0012 | Recall(Attack)=0.9983\n",
            "Saved to: /content/artifacts\n"
          ]
        }
      ]
    }
  ]
}